{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq LSTM vs VAE for Learning Behavior Prediction\n",
    "\n",
    "This notebook compares two sequence generation models on the Open University Learning Analytics Dataset (OULAD):\n",
    "- **Seq2Seq LSTM**: Deterministic single-path prediction\n",
    "- **Seq2Seq VAE**: Probabilistic multi-path generation\n",
    "\n",
    "## Objectives\n",
    "1. Train both models on the same dataset\n",
    "2. Compare single-path prediction accuracy (MSE)\n",
    "3. Analyze diversity and coverage of VAE generations\n",
    "4. Visualize and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download OULAD Dataset\n",
    "\n",
    "This section automatically downloads the OULAD dataset from Kaggle and extracts the required CSV files.\n",
    "\n",
    "**Required files:**\n",
    "- `studentInfo.csv`: Student demographics and registration info\n",
    "- `studentVle.csv`: Student VLE interaction logs (clicks)\n",
    "- `studentAssessment.csv`: Assessment submissions and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data already exists\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Define required files\n",
    "data_dir = Path('data/raw')\n",
    "required_files = [\n",
    "    'studentInfo.csv',\n",
    "    'studentVle.csv',\n",
    "    'studentAssessment.csv'\n",
    "]\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if all required files exist\n",
    "all_files_exist = all((data_dir / f).exists() for f in required_files)\n",
    "\n",
    "if all_files_exist:\n",
    "    print(\"\u2713 All required data files already exist!\")\n",
    "    for f in required_files:\n",
    "        file_path = data_dir / f\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {f}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"\u26a0 Some data files are missing. Downloading from Kaggle...\")\n",
    "    \n",
    "    # Download dataset from Kaggle\n",
    "    zip_path = 'data/oulad_dataset.zip'\n",
    "    \n",
    "    print(\"\\nDownloading OULAD dataset...\")\n",
    "    print(\"This may take a few minutes depending on your internet connection.\")\n",
    "    \n",
    "    # Use curl to download (works on most systems)\n",
    "    !curl -L -o {zip_path} \\\n",
    "        https://www.kaggle.com/api/v1/datasets/download/anlgrbz/student-demographics-online-education-dataoulad\n",
    "    \n",
    "    # Check if download was successful\n",
    "    if os.path.exists(zip_path):\n",
    "        print(f\"\\n\u2713 Download complete: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        # Extract the zip file\n",
    "        print(\"\\nExtracting files...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            # List all files in the zip\n",
    "            all_files = zip_ref.namelist()\n",
    "            print(f\"Found {len(all_files)} files in archive\")\n",
    "            \n",
    "            # Extract only the required files\n",
    "            for file in all_files:\n",
    "                # Get just the filename without path\n",
    "                filename = os.path.basename(file)\n",
    "                \n",
    "                if filename in required_files:\n",
    "                    # Read file from zip and write to data/raw/\n",
    "                    with zip_ref.open(file) as source:\n",
    "                        target_path = data_dir / filename\n",
    "                        with open(target_path, 'wb') as target:\n",
    "                            target.write(source.read())\n",
    "                    print(f\"  \u2713 Extracted: {filename}\")\n",
    "        \n",
    "        # Clean up zip file\n",
    "        os.remove(zip_path)\n",
    "        print(\"\\n\u2713 Cleanup complete. Zip file removed.\")\n",
    "        \n",
    "        # Verify all files now exist\n",
    "        all_files_exist = all((data_dir / f).exists() for f in required_files)\n",
    "        if all_files_exist:\n",
    "            print(\"\\n\u2713 All required files successfully extracted!\")\n",
    "            for f in required_files:\n",
    "                file_path = data_dir / f\n",
    "                size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  - {f}: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(\"\\n\u26a0 Warning: Some files are still missing!\")\n",
    "            missing = [f for f in required_files if not (data_dir / f).exists()]\n",
    "            print(f\"Missing files: {missing}\")\n",
    "    else:\n",
    "        print(\"\\n\u2717 Download failed!\")\n",
    "        print(\"\\nAlternative: Download manually from:\")\n",
    "        print(\"https://www.kaggle.com/datasets/anlgrbz/student-demographics-online-education-dataoulad\")\n",
    "        print(f\"Then extract the required files to: {data_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP FOR GOOGLE COLAB AND LOCAL ENVIRONMENTS\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"\ud83d\udd27 Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"\ud83d\udd27 Running locally\")\n",
    "\n",
    "# ============================================================================\n",
    "# INSTALL DEPENDENCIES\n",
    "# ============================================================================\n",
    "if IN_COLAB:\n",
    "    print(\"\\n\ud83d\udce6 Installing dependencies...\")\n",
    "    !pip install -q torch numpy pandas matplotlib seaborn scikit-learn tqdm\n",
    "    print(\"\u2713 Dependencies installed\")\n",
    "\n",
    "# ============================================================================\n",
    "# CLONE REPOSITORY (if needed on Colab)\n",
    "# ============================================================================\n",
    "if IN_COLAB:\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"\\n\ud83d\udcc2 Current directory: {current_dir}\")\n",
    "    \n",
    "    # Check if we're already in the repository (src exists in current dir)\n",
    "    if not os.path.exists('src'):\n",
    "        print(\"\u26a0\ufe0f  src/ not found. Cloning repository...\")\n",
    "        !git clone https://github.com/Qmo37/Seq2Seq_LSTM_VAE.git /content/Seq2Seq_LSTM_VAE\n",
    "        os.chdir('/content/Seq2Seq_LSTM_VAE')\n",
    "        print(f\"\u2713 Repository cloned and changed to: {os.getcwd()}\")\n",
    "    else:\n",
    "        print(\"\u2713 Repository already present\")\n",
    "\n",
    "# ============================================================================\n",
    "# ADD SRC TO PYTHON PATH\n",
    "# ============================================================================\n",
    "print(\"\\n\ud83d\udd0d Setting up Python path...\")\n",
    "\n",
    "# Get current working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"Working directory: {cwd}\")\n",
    "\n",
    "# Find src directory - check in order of likelihood\n",
    "src_candidates = [\n",
    "    cwd / 'src',                    # In current directory (most common)\n",
    "    cwd.parent / 'src',             # One level up (if in notebooks/)\n",
    "    cwd / '..' / 'src',             # Relative path up\n",
    "]\n",
    "\n",
    "src_path = None\n",
    "for candidate in src_candidates:\n",
    "    candidate_resolved = candidate.resolve()  # Resolve symlinks and ..\n",
    "    if candidate_resolved.exists() and candidate_resolved.is_dir():\n",
    "        src_path = str(candidate_resolved)\n",
    "        print(f\"\u2713 Found src at: {src_path}\")\n",
    "        break\n",
    "\n",
    "if src_path:\n",
    "    # Add to Python path if not already there\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        print(f\"\u2713 Added to Python path\")\n",
    "    \n",
    "    # Verify required modules exist\n",
    "    required_modules = ['data', 'models', 'utils']\n",
    "    all_found = True\n",
    "    print(\"\\nVerifying modules:\")\n",
    "    for module in required_modules:\n",
    "        module_path = Path(src_path) / module\n",
    "        if module_path.exists():\n",
    "            print(f\"  \u2713 {module}/\")\n",
    "        else:\n",
    "            print(f\"  \u2717 {module}/ MISSING!\")\n",
    "            all_found = False\n",
    "    \n",
    "    if all_found:\n",
    "        print(\"\\n\u2705 Setup complete! Ready to import custom modules.\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  Warning: Some modules are missing!\")\n",
    "else:\n",
    "    print(\"\\n\u274c ERROR: Could not find src/ directory!\")\n",
    "    print(f\"\\nSearched in:\")\n",
    "    for candidate in src_candidates:\n",
    "        print(f\"  - {candidate} (exists: {candidate.exists()})\")\n",
    "    print(f\"\\nDirectory contents of {cwd}:\")\n",
    "    for item in cwd.iterdir():\n",
    "        print(f\"  - {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import custom modules (from src/)\n",
    "from data import load_and_preprocess_data, LearningBehaviorDataset\n",
    "from models import Seq2SeqLSTM, Seq2SeqVAE\n",
    "from utils import (\n",
    "    train_lstm, train_vae, set_seed,\n",
    "    evaluate_model,\n",
    "    plot_training_curves, plot_comparison, plot_diversity_analysis\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"\u2713 All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed hyperparameters (as per requirements)\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data_path': 'data/raw',\n",
    "    'input_weeks': 4,\n",
    "    'output_weeks': 2,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 1e-3,\n",
    "    'epochs': 20,  # Adjustable: 5-30+\n",
    "    'random_seed': 42,\n",
    "    \n",
    "    # Model architecture\n",
    "    'hidden_size': 64,  # Adjustable\n",
    "    'latent_dim': 16,   # Adjustable (VAE only)\n",
    "    'num_layers': 1,\n",
    "    'dropout': 0.0,\n",
    "    \n",
    "    # VAE specific\n",
    "    'beta': 1.0,  # Weight for KL divergence\n",
    "    \n",
    "    # Evaluation\n",
    "    'n_samples': 20,  # Number of VAE samples for evaluation\n",
    "    \n",
    "    # Device\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "set_seed(CONFIG['random_seed'])\n",
    "\n",
    "# Load and preprocess data\n",
    "print(\"Loading and preprocessing OULAD dataset...\")\n",
    "data = load_and_preprocess_data(\n",
    "    data_path=CONFIG['data_path'],\n",
    "    input_weeks=CONFIG['input_weeks'],\n",
    "    output_weeks=CONFIG['output_weeks'],\n",
    "    random_seed=CONFIG['random_seed']\n",
    ")\n",
    "\n",
    "print(f\"\\nData shapes:\")\n",
    "print(f\"  Train: X={data['X_train'].shape}, y={data['y_train'].shape}\")\n",
    "print(f\"  Val:   X={data['X_val'].shape}, y={data['y_val'].shape}\")\n",
    "print(f\"  Test:  X={data['X_test'].shape}, y={data['y_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets and dataloaders\n",
    "train_dataset = LearningBehaviorDataset(data['X_train'], data['y_train'])\n",
    "val_dataset = LearningBehaviorDataset(data['X_val'], data['y_val'])\n",
    "test_dataset = LearningBehaviorDataset(data['X_test'], data['y_test'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"Number of batches: Train={len(train_loader)}, Val={len(val_loader)}, Test={len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "### 4.1 Seq2Seq LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM model\n",
    "input_size = data['X_train'].shape[2]  # Number of features\n",
    "\n",
    "lstm_model = Seq2SeqLSTM(\n",
    "    input_size=input_size,\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    output_size=1,  # Predicting clicks only\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "\n",
    "print(f\"LSTM Model Architecture:\")\n",
    "print(lstm_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM\n",
    "print(\"Training Seq2Seq LSTM...\")\n",
    "lstm_history = train_lstm(\n",
    "    model=lstm_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device'],\n",
    "    output_weeks=CONFIG['output_weeks']\n",
    ")\n",
    "\n",
    "# Save model\n",
    "torch.save(lstm_model.state_dict(), 'results/checkpoints/lstm_model.pt')\n",
    "print(\"\\nLSTM model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Seq2Seq VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VAE model\n",
    "vae_model = Seq2SeqVAE(\n",
    "    input_size=input_size,\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    latent_dim=CONFIG['latent_dim'],\n",
    "    output_size=1,\n",
    "    num_layers=CONFIG['num_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "\n",
    "print(f\"VAE Model Architecture:\")\n",
    "print(vae_model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in vae_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VAE\n",
    "print(\"Training Seq2Seq VAE...\")\n",
    "vae_history = train_vae(\n",
    "    model=vae_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device'],\n",
    "    output_weeks=CONFIG['output_weeks'],\n",
    "    beta=CONFIG['beta']\n",
    ")\n",
    "\n",
    "# Save model\n",
    "torch.save(vae_model.state_dict(), 'results/checkpoints/vae_model.pt')\n",
    "print(\"\\nVAE model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plot_training_curves(\n",
    "    lstm_history=lstm_history,\n",
    "    vae_history=vae_history,\n",
    "    save_path='results/figures/training_curves.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LSTM\n",
    "print(\"Evaluating LSTM on test set...\")\n",
    "lstm_results = evaluate_model(\n",
    "    model=lstm_model,\n",
    "    data_loader=test_loader,\n",
    "    device=CONFIG['device'],\n",
    "    output_weeks=CONFIG['output_weeks'],\n",
    "    is_vae=False\n",
    ")\n",
    "\n",
    "print(f\"\\nLSTM Results:\")\n",
    "print(f\"  MSE: {lstm_results['mse']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate VAE\n",
    "print(\"Evaluating VAE on test set...\")\n",
    "vae_results = evaluate_model(\n",
    "    model=vae_model,\n",
    "    data_loader=test_loader,\n",
    "    device=CONFIG['device'],\n",
    "    output_weeks=CONFIG['output_weeks'],\n",
    "    n_samples=CONFIG['n_samples'],\n",
    "    is_vae=True\n",
    ")\n",
    "\n",
    "print(f\"\\nVAE Results:\")\n",
    "print(f\"  MSE (mean prediction): {vae_results['mse']:.6f}\")\n",
    "print(f\"  Best-of-N MSE: {vae_results['best_of_n_mse']:.6f}\")\n",
    "print(f\"  Diversity (std): {vae_results['diversity']:.6f}\")\n",
    "print(f\"  Coverage (95% CI): {vae_results['coverage']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison plot\n",
    "plot_comparison(\n",
    "    lstm_results=lstm_results,\n",
    "    vae_results=vae_results,\n",
    "    save_path='results/figures/model_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diversity analysis\n",
    "plot_diversity_analysis(\n",
    "    vae_samples=vae_results['samples'],\n",
    "    targets=vae_results['targets'],\n",
    "    save_path='results/figures/diversity_analysis.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'Best-of-N MSE', 'Diversity', 'Coverage'],\n",
    "    'LSTM': [\n",
    "        f\"{lstm_results['mse']:.6f}\",\n",
    "        'N/A',\n",
    "        '0 (deterministic)',\n",
    "        'N/A'\n",
    "    ],\n",
    "    'VAE': [\n",
    "        f\"{vae_results['mse']:.6f}\",\n",
    "        f\"{vae_results['best_of_n_mse']:.6f}\",\n",
    "        f\"{vae_results['diversity']:.6f}\",\n",
    "        f\"{vae_results['coverage']:.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(summary.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "**Single-Path Prediction Accuracy:**\n",
    "- Compare LSTM MSE vs VAE MSE (mean prediction)\n",
    "- Which model is more accurate for deterministic prediction?\n",
    "\n",
    "**Diversity and Multi-Path Generation:**\n",
    "- VAE Best-of-N MSE: How much better can VAE do when allowed multiple attempts?\n",
    "- VAE Diversity: How varied are the generated sequences?\n",
    "- VAE Coverage: Do the generated samples capture the true uncertainty?\n",
    "\n",
    "**Trade-offs:**\n",
    "- LSTM: Simple, fast, deterministic \u2192 Good for point predictions\n",
    "- VAE: Complex, slower, probabilistic \u2192 Good for uncertainty quantification and exploring multiple futures\n",
    "\n",
    "**Practical Implications:**\n",
    "- When to use LSTM: Need single best prediction, computational efficiency\n",
    "- When to use VAE: Need to understand uncertainty, explore multiple scenarios, risk assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numerical results\n",
    "import json\n",
    "\n",
    "results_summary = {\n",
    "    'config': CONFIG,\n",
    "    'lstm': {\n",
    "        'mse': float(lstm_results['mse']),\n",
    "        'n_parameters': sum(p.numel() for p in lstm_model.parameters())\n",
    "    },\n",
    "    'vae': {\n",
    "        'mse': float(vae_results['mse']),\n",
    "        'best_of_n_mse': float(vae_results['best_of_n_mse']),\n",
    "        'diversity': float(vae_results['diversity']),\n",
    "        'coverage': float(vae_results['coverage']),\n",
    "        'n_parameters': sum(p.numel() for p in vae_model.parameters())\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('results/results_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Results saved to results/results_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary table\n",
    "summary.to_csv('results/comparison_table.csv', index=False)\n",
    "print(\"Comparison table saved to results/comparison_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Implementation of Seq2Seq LSTM and VAE for learning behavior prediction\n",
    "2. Training and evaluation on OULAD dataset\n",
    "3. Comprehensive comparison of single-path vs multi-path generation\n",
    "4. Visualization and analysis of model strengths and weaknesses\n",
    "\n",
    "**Next Steps for Report:**\n",
    "- Copy figures from `results/figures/` to your Word document\n",
    "- Use `results/results_summary.json` and `results/comparison_table.csv` for metrics\n",
    "- Discuss advantages and disadvantages of each model\n",
    "- Analyze when to use each model in practice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}